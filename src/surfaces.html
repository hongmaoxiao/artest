<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
  <title>three.ar.js - Surfaces</title>
  <style>
    body {
      font-family: monospace;
      margin: 0;
      overflow: hidden;
      position: fixed;
      width: 100%;
      height: 100vh;
      -webkit-user-select: none;
      user-select: none;
    }

    #info {
      position: absolute;
      left: 50%;
      bottom: 0;
      transform: translate(-50%, 0);
      margin: 1em;
      z-index: 10;
      display: block;
      width: 100%;
      line-height: 2em;
      text-align: center;
    }

    #info * {
      color: #fff;
    }

    .title {
      background-color: rgba(40, 40, 40, 0.4);
      padding: 0.4em 0.6em;
      border-radius: 0.1em;
    }

    .links {
      background-color: rgba(40, 40, 40, 0.6);
      padding: 0.4em 0.6em;
      border-radius: 0.1em;
    }

    canvas {
      position: absolute;
      top: 0;
      left: 0;
    }
  </style>
</head>

<body>
  <div id="info">
    <span class="title">Render detected surfaces.</span><br/>
    <span class="links">
      <a href="https://github.com/google-ar/three.ar.js">three.ar.js</a> -
      <a href="https://developers.google.com/ar/develop/web/getting-started#examples">examples</a>
    </span>
  </div>
  <script href="https://cdn.jsdelivr.net/npm/three.ar.js@latest/dist/three.ar.min.js"></script>
  <script type="text/javascript">
    var vrDisplay, vrControls, arView;
    var canvas, camera, scene, renderer;
    THREE.ARUtils.getARDisplay().then(function (display) {
      if (display) {
        vrDisplay = display;
        init();
      } else {
        THREE.ARUtils.displayUnsupportedMessage();
      }
    });
    function init() {
      // Setup the three.js rendering environment
      renderer = new THREE.WebGLRenderer({ alpha: true });
      renderer.setPixelRatio(window.devicePixelRatio);
      renderer.setSize(window.innerWidth, window.innerHeight);
      renderer.autoClear = false;
      canvas = renderer.domElement;
      document.body.appendChild(canvas);
      scene = new THREE.Scene();
      // Turn on the debugging panel
      var arDebug = new THREE.ARDebug(vrDisplay, scene, {
        showLastHit: false,
        showPoseStatus: false,
        showPlanes: true,
      });
      document.body.appendChild(arDebug.getElement());
      // Creating the ARView, which is the object that handles
      // the rendering of the camera stream behind the three.js
      // scene
      arView = new THREE.ARView(vrDisplay, renderer);
      // The ARPerspectiveCamera is very similar to THREE.PerspectiveCamera,
      // except when using an AR-capable browser, the camera uses
      // the projection matrix provided from the device, so that the
      // perspective camera's depth planes and field of view matches
      // the physical camera on the device.
      camera = new THREE.ARPerspectiveCamera(
        vrDisplay,
        60,
        window.innerWidth / window.innerHeight,
        vrDisplay.depthNear,
        vrDisplay.depthFar
      );
      // VRControls is a utility from three.js that applies the device's
      // orientation/position to the perspective camera, keeping our
      // real world and virtual world in sync.
      vrControls = new THREE.VRControls(camera);
      // Bind our event handlers
      window.addEventListener('resize', onWindowResize, false);
      // Kick off the render loop!
      update();
    }
    /**
     * The render loop, called once per frame. Handles updating
     * our scene and rendering.
     */
    function update() {
      // Clears color from the frame before rendering the camera (arView) or scene.
      renderer.clearColor();
      // Render the device's camera stream on screen first of all.
      // It allows to get the right pose synchronized with the right frame.
      arView.render();
      // Update our camera projection matrix in the event that
      // the near or far planes have updated
      camera.updateProjectionMatrix();
      // Update our perspective camera's positioning
      vrControls.update();
      // Render our three.js virtual scene
      renderer.clearDepth();
      renderer.render(scene, camera);
      // Kick off the requestAnimationFrame to call this function
      // when a new VRDisplay frame is rendered
      vrDisplay.requestAnimationFrame(update);
    }
    /**
     * On window resize, update the perspective camera's aspect ratio,
     * and call `updateProjectionMatrix` so that we can get the latest
     * projection matrix provided from the device
     */
    function onWindowResize () {
      camera.aspect = window.innerWidth / window.innerHeight;
      camera.updateProjectionMatrix();
      renderer.setSize(window.innerWidth, window.innerHeight);
    }
  </script>
</body>

</html>
